{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavior Cloning - Project - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writeup File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behavioral Cloning Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Use the simulator to collect data of good driving behavior\n",
    "* Build, a convolution neural network in Keras that predicts steering angles from images\n",
    "* Train and validate the model with a training and validation set\n",
    "* Test that the model successfully drives around track one without leaving the road\n",
    "* Summarize the results with a written report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Files Submitted & Code Quality\n",
    "1. My project includes the following files:\n",
    "\n",
    " * model.py containing the script to create and train the model\n",
    " * drive.py for driving the car in autonomous mode\n",
    " * model.h5 containing a trained convolution neural network\n",
    " * writeup_report.md or writeup_report.pdf summarizing the results\n",
    " * video.mp4 - Video of car running on track\n",
    " \n",
    "2. Submission includes functional code\n",
    "\n",
    " * Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing - \n",
    " python drive.py model.h5\n",
    " \n",
    "3. Submission code is usable and readable\n",
    " * The model.py file contains the code for training and saving the convolution neural network. The file shows the pipeline I used for training and validating the model, and it contains comments to explain how the code works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Architecture and Training Strategy\n",
    "\n",
    "1. An appropriate model architecture has been employed. Description of each layer of the model.\n",
    " * Lamdba layer. This layer will normalized the image to have near 0 mean. This optimizes the gradient descent process.\n",
    " * 2D Convolution layer with a filter size of 5x5 and stride of 2x2. Output of this layer has a depth of 32.This layer is followed by Relu Activation layer to introduce non linearity in the model and MaxPooling to reduce overfitting.\n",
    " * Another 2D Convolution layer with a filter size of 5x5 and stride of 2x2. Output of this layer has a depth of 64. This layer is also followed by Relu Activation layer to introduce non linearity in the model and MaxPooling to reduce overfitting.\n",
    " * Flatten layer, this will flatten the output from Convoltion layer and it wil be passed to Dense layer.\n",
    " * The model has 3 Dense layer with output 128,64 and 1 respectively.\n",
    " \n",
    "2. Attempts to reduce overfitting in the model\n",
    " * The model contains dropout layer in order to reduce overfitting. The model was tested by running it through the simulator and ensuring that the vehicle could stay on the track\n",
    "\n",
    "3. Model parameter tuning\n",
    " * The model used an adam optimizer, so the learning rate was not tuned manually\n",
    " \n",
    "4. Appropriate training data\n",
    " * Training data was chosen to keep the vehicle driving on the road. I used a combination of center lane driving, flipped images so angles are not steering angels are not biased. Images of all the 3 cameras - center,left and right has been used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Architecture and Training Strategy\n",
    "\n",
    "1. Solution Design Approach and final approch.\n",
    "\n",
    " The strategy for deriving a model architecture is based on LeNet-5. My first step is to use a 2D Convolution layer with a small filter, this will detect rudimentary feaurtes on the road (as most of the sky and tress are cropped). Then I have a second 2D Convolution layer to detect more higher level features like turns and straight road. As images are are simple and there are not objects like pedestrians and traffic signs, I do not find any requirement of more ConNets to detect complex features. In order to minimize the output, MaxPooling layers are added after each CovNet and Relu layers are added to introduced non linearity. There are 3 Dense layer in my model to gradually give the final result, which is a single number indicating the steering angle the car should take. \n",
    " \n",
    " The final step was to run the simulator to see how well the car was driving around track one. Initially, the vehicle was not running in a straight line and was left biased. To imporve this, I added flipped images and added images of left and right cameras as well, I corrected the steering angle for left and right images as the value of steering is with respect to center camera. At the end of the process, the vehicle is able to drive autonomously around the track without leaving the road.\n",
    " \n",
    " The final model architecture (model.py lines 106-132) consisted of a convolution neural network with the following layers and layer sizes \n",
    " \n",
    " 1. Convolution2D. Output depth - 32\n",
    " 2. Activation - Relu\n",
    " 3. MaxPooling - 2x2\n",
    " 4. Convolution2D. Output depth - 64\n",
    " 5. Activation - Relu\n",
    " 6. MaxPooling - 2x2\n",
    " 7. Flatten\n",
    " 8. Dense. Output -128\n",
    " 9. Dropout\n",
    " 10. Dense - Output - 64\n",
    " 11. Dense - Output - 1\n",
    " \n",
    "2. Creation of the Training Set & Training Process\n",
    "    To capture good driving behavior, I first recorded two laps on track one using center lane driving. Here is an example image of center lane driving\n",
    " \n",
    " ![](images/CD1.jpg)\n",
    " \n",
    " I then recorded the vehicle recovering from the left side and right sides of the road back to center so that the vehicle would learn to come to center when it goes in corner. These images show what a recovery looks like starting from right and coming to center.\n",
    "\n",
    " ![](images/R1.jpeg) ![](images/R2.jpeg) ![](images/R3.jpeg)\n",
    " \n",
    " To augment the data sat, I also flipped images and angles thinking that this would ... For example, here is an image that has then been flipped:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used model.fit_generator to train and validatate my model. The graph of training loss and validation loss vs number of Epochs (which is 2 in my case) is like this \n",
    "![](images/training_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion \n",
    "\n",
    "I can clearly say that, the prime part of any neural network is how well we train it and keeping it mind it does not overfit, for this we need more data, variety of data and correct data. To improvise this model, to run on more complicated tracks, we will need more data where we have car, pedastrians etc and to understand these complex things, our network will need more layers, where higher layer will be detecing higher feaures like another car or a traffic sign. \n",
    "\n",
    "Just like my neural network, I will also have to continue my training with more input data to make this happen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
